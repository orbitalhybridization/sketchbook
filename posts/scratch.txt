 <p hidden>

          Lately, I've been thinking about representation; the computational spaces that minds use to think.
          
          Good links:
          - https://scholar.google.com/scholar?hl=en&as_sdt=0%2C34&q=default+mode+network+brain+language+non-linguistic&btnG=
          - https://www.nature.com/articles/s41583-024-00802-4
          - https://www.biorxiv.org/content/10.1101/2023.08.21.553821v1.abstract


          For the past several months, I have been thinking about modeling the many facets of human
          interaction. Proxemics, prosody, even the collaborative arts (think jam sessions between 
          musicians).
  
          I've especially been thinking about this in terms of machines. 
          
          What are the latent spaces that modern
          artificial intelligences "think" in? These representational spaces are known as latent spaces. Mathematically,
          these are known as embeddings, which is a way of defining a space with special properties that make
          it computable. Common latent spaces are Word2Vec, GloVe, and Variational Autoencoders (via Wikipedia).
  
          What I'm thinking about, though, is the representation for information that is spatiotemporally
          polymorphic. A common problem in AI is context, a feature of experience that humans perceive, recall,
          create, and destroy, with considerable ease at an eary age.

        </p>
